{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/widerface/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/MAFA/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Celeba/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/shangchao_data/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface_register/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/hand/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/background/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/animals/train',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/PandaEmoji/train',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_1/train',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_2/train',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/synthetise/train',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/250508/train',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/250512/train'],\n",
       " 'weights': [5, 0.5, 0.5, 0.2, 2, 2, 3, 1, 2, 2, 1, 1, 0.1, 2, 2],\n",
       " 'val': ['/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/MAFA/val',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Celeba/val',\n",
       "  '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/shangchao_data/val',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_1/val',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_2/val',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/synthetise/val',\n",
       "  '/mnt/pai-storage-12/data/qrcode_data/qrcode/250508/val'],\n",
       " 'names': {0: 'face', 1: 'qrcode'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "config_fp = '/data/wangjiazhi/projs/yolov8_0512/configs/face_qrcode2.yaml'\n",
    "with open(config_fp, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/widerface/train': 5,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/MAFA/train': 0.5,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Celeba/train': 0.5,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/shangchao_data/train': 0.2,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface/train': 2,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface_register/train': 2,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/hand/train': 3,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/background/train': 1,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/animals/train': 2,\n",
       " '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/PandaEmoji/train': 2,\n",
       " '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_1/train': 1,\n",
       " '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_2/train': 1,\n",
       " '/mnt/pai-storage-12/data/qrcode_data/qrcode/synthetise/train': 0.1,\n",
       " '/mnt/pai-storage-12/data/qrcode_data/qrcode/250508/train': 2,\n",
       " '/mnt/pai-storage-12/data/qrcode_data/qrcode/250512/train': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_2_weights = {}\n",
    "for train_dir, weights in zip(config['train'], config['weights']):\n",
    "    train_dir_2_weights[train_dir] = weights\n",
    "train_dir_2_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/widerface/train\n",
      "{'img_count': 12682, 'txt_count': 12682, 'empty_label_count': 0, 'face_bbox_count': 81039, 'qrcode_bbox_count': 0, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/MAFA/train\n",
      "{'img_count': 17789, 'txt_count': 17789, 'empty_label_count': 0, 'face_bbox_count': 27599, 'qrcode_bbox_count': 0, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Celeba/train\n",
      "{'img_count': 39095, 'txt_count': 39095, 'empty_label_count': 0, 'face_bbox_count': 39095, 'qrcode_bbox_count': 0, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/shangchao_data/train\n",
      "{'img_count': 94737, 'txt_count': 94737, 'empty_label_count': 0, 'face_bbox_count': 179581, 'qrcode_bbox_count': 0, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface/train\n",
      "{'img_count': 50656, 'txt_count': 50656, 'empty_label_count': 0, 'face_bbox_count': 50656, 'qrcode_bbox_count': 0, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface_register/train\n",
      "{'img_count': 34752, 'txt_count': 34752, 'empty_label_count': 0, 'face_bbox_count': 35013, 'qrcode_bbox_count': 0, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/hand/train\n",
      "{'img_count': 4915, 'txt_count': 0, 'empty_label_count': 0, 'face_bbox_count': 0, 'qrcode_bbox_count': 0, 'none_label_count': 4915}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/background/train\n",
      "{'img_count': 4358, 'txt_count': 0, 'empty_label_count': 0, 'face_bbox_count': 0, 'qrcode_bbox_count': 0, 'none_label_count': 4358}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/animals/train\n",
      "{'img_count': 5778, 'txt_count': 0, 'empty_label_count': 0, 'face_bbox_count': 0, 'qrcode_bbox_count': 0, 'none_label_count': 5778}\n",
      "/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/PandaEmoji/train\n",
      "{'img_count': 2428, 'txt_count': 0, 'empty_label_count': 0, 'face_bbox_count': 0, 'qrcode_bbox_count': 0, 'none_label_count': 2428}\n",
      "/mnt/pai-storage-12/data/qrcode_data/qrcode/public_1/train\n",
      "{'img_count': 2623, 'txt_count': 2631, 'empty_label_count': 0, 'face_bbox_count': 0, 'qrcode_bbox_count': 3500, 'none_label_count': -8}\n",
      "/mnt/pai-storage-12/data/qrcode_data/qrcode/public_2/train\n",
      "{'img_count': 3610, 'txt_count': 3610, 'empty_label_count': 0, 'face_bbox_count': 0, 'qrcode_bbox_count': 5589, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/qrcode_data/qrcode/synthetise/train\n",
      "{'img_count': 80117, 'txt_count': 80117, 'empty_label_count': 0, 'face_bbox_count': 83665, 'qrcode_bbox_count': 80117, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/qrcode_data/qrcode/250508/train\n",
      "{'img_count': 4382, 'txt_count': 4382, 'empty_label_count': 25, 'face_bbox_count': 290, 'qrcode_bbox_count': 4125, 'none_label_count': 0}\n",
      "/mnt/pai-storage-12/data/qrcode_data/qrcode/250512/train\n",
      "{'img_count': 3667, 'txt_count': 3667, 'empty_label_count': 90, 'face_bbox_count': 26, 'qrcode_bbox_count': 3657, 'none_label_count': 0}\n"
     ]
    }
   ],
   "source": [
    "train_dirs = config['train']\n",
    "val_dirs = config['val']\n",
    "train_weights = config['weights']\n",
    "assert len(train_dirs) == len(train_weights), f\"{len(train_dirs)} != {len(train_weights)}\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_directory(directory):\n",
    "    img_root = os.path.join(directory, 'images')\n",
    "    label_root = os.path.join(directory, 'labels')\n",
    "\n",
    "    ### count image files\n",
    "    # image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}\n",
    "    image_extensions = {'.jpg', '.png', '.jpeg'}\n",
    "    image_count = 0\n",
    "    total_count = 0\n",
    "    other_extensions = set()\n",
    "    \n",
    "    for root, _, files in os.walk(img_root):\n",
    "        for file in files:\n",
    "            total_count += 1\n",
    "            ext = os.path.splitext(file)[1].lower()\n",
    "            \n",
    "            if ext in image_extensions:\n",
    "                image_count += 1\n",
    "            else:\n",
    "                other_extensions.add(ext)\n",
    "    \n",
    "    if total_count != image_count:\n",
    "        print(f\"Total files: {total_count}, Image files: {image_count}, Other files: {len(other_extensions)}\")\n",
    "        print(f\"Other extensions: {other_extensions}\")\n",
    "    # else:\n",
    "    #     print(f\"Image files: {image_count}\")\n",
    "\n",
    "    ### count txt files\n",
    "    txt_count = 0\n",
    "    total_count = 0\n",
    "    other_extensions = set()\n",
    "    empty_label_count = 0  # 负样本图片数量（没有目标）\n",
    "    face_bbox_count = 0\n",
    "    qrcode_bbox_count = 0\n",
    "    for root, _, files in os.walk(label_root):\n",
    "        for file in files:\n",
    "            total_count += 1\n",
    "            ext = os.path.splitext(file)[1].lower()\n",
    "            if ext == '.txt':\n",
    "                txt_count += 1\n",
    "            else:\n",
    "                other_extensions.add(ext)\n",
    "            \n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [line.strip() for line in lines]\n",
    "                if len(lines) == 0:\n",
    "                    empty_label_count += 1\n",
    "                else:\n",
    "                    for line in lines:\n",
    "                        if line.startswith('0'):\n",
    "                            face_bbox_count += 1\n",
    "                        elif line.startswith('1'):\n",
    "                            qrcode_bbox_count += 1\n",
    "                        else:\n",
    "                            print(f\"Invalid line: {line}\")\n",
    "\n",
    "    if total_count != txt_count:\n",
    "        print(f\"Total files: {total_count}, Txt files: {txt_count}, Other files: {len(other_extensions)}\")\n",
    "        print(f\"Other extensions: {other_extensions}\")\n",
    "    # else:\n",
    "    #     print(f\"Txt files: {txt_count}\")\n",
    "\n",
    "    return {\n",
    "        'img_count': image_count,\n",
    "        'txt_count': txt_count,\n",
    "        'empty_label_count': empty_label_count,\n",
    "        'face_bbox_count': face_bbox_count,\n",
    "        'qrcode_bbox_count': qrcode_bbox_count\n",
    "    }\n",
    "\n",
    "\n",
    "results = {}\n",
    "for train_dir in train_dirs:\n",
    "    print(train_dir)\n",
    "    stats = analyze_directory(train_dir)\n",
    "    stats['none_label_count'] = stats['img_count'] - stats['txt_count']\n",
    "    print(stats)\n",
    "    results[train_dir] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_img_count: 361589, total_txt_count: 344118\n"
     ]
    }
   ],
   "source": [
    "total_img_count = sum([stats['img_count'] for stats in results.values()])\n",
    "total_txt_count = sum([stats['txt_count'] for stats in results.values()])\n",
    "print(f\"total_img_count: {total_img_count}, total_txt_count: {total_txt_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bbox count\n",
    "### without weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_img_count = 0\n",
    "qrcode_img_count = 0\n",
    "face_box_count = 0\n",
    "qrcode_box_count = 0\n",
    "background_img_count = 0\n",
    "\n",
    "for train_dir, stats in results.items():\n",
    "    if ('Facedetect' in train_dir and 'qrcode' in train_dir) or ('Facedetect' not in train_dir and 'qrcode' not in train_dir):\n",
    "        raise ValueError(\"Unexpected train_dir: \", train_dir)\n",
    "    elif 'Facedetect' in train_dir:\n",
    "        # print(\"Facedetect train_dir: \", train_dir)\n",
    "        face_img_count += stats['img_count']\n",
    "    elif 'qrcode' in train_dir:\n",
    "        # print(\"qrcode train_dir: \", train_dir)\n",
    "        qrcode_img_count += stats['img_count']\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected train_dir: \", train_dir)\n",
    "\n",
    "    face_box_count += stats['face_bbox_count']\n",
    "    qrcode_box_count += stats['qrcode_bbox_count']\n",
    "    background_img_count += stats['none_label_count'] + stats['empty_label_count']\n",
    "\n",
    "print(f\"face_img_count: {face_img_count}, qrcode_img_count: {qrcode_img_count}, face_box_count: {face_box_count}, qrcode_box_count: {qrcode_box_count}, background_img_count: {background_img_count}\")\n",
    "total_bbox_count = face_box_count + qrcode_box_count\n",
    "print(f\"Face bbox ratio: {face_box_count / total_bbox_count:.2%}, Qrcode bbox ratio: {qrcode_box_count / total_bbox_count:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_2_weights_0 = {\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/widerface/train': 2,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/MAFA/train': 1,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Celeba/train': 1,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/shangchao_data/train': 1,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface/train': 5,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface_register/train': 2,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/hand/train': 3,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/background/train': 0.5,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/animals/train': 2,  # 5778\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_1/train': 1,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_2/train': 1,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/synthetise/train': 0.2,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/250508/train': 1,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/250512/train': 1,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/PandaEmoji/train': 1,\n",
    "}\n",
    "train_dir_2_weights_old = {\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/widerface/train': 8.0,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/MAFA/train': 0.56,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Celeba/train': 0.25,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/shangchao_data/train': 0.2,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface/train': 1.0,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/Uface_register/train': 0.28,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/hand/train': 3.0,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/background/train': 1.0,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/animals/train': 2.0,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_1/train': 2.0,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/public_2/train': 2.0,\n",
    "    '/mnt/pai-storage-12/data/qrcode_data/qrcode/synthetise/train': 0.37,\n",
    "    '/mnt/pai-storage-12/data/Facedetect_data/yolo-face_data/PandaEmoji/train': 2.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_img_count = 0\n",
    "qrcode_img_count = 0\n",
    "face_box_count = 0\n",
    "qrcode_box_count = 0\n",
    "background_img_count = 0\n",
    "\n",
    "for train_dir, stats in results.items():\n",
    "    weight = train_dir_2_weights[train_dir]\n",
    "    if ('Facedetect' in train_dir and 'qrcode' in train_dir) or ('Facedetect' not in train_dir and 'qrcode' not in train_dir):\n",
    "        raise ValueError(\"Unexpected train_dir: \", train_dir)\n",
    "    elif 'Facedetect' in train_dir:\n",
    "        # print(\"Facedetect train_dir: \", train_dir)\n",
    "        face_img_count += stats['img_count'] * weight\n",
    "    elif 'qrcode' in train_dir:\n",
    "        # print(\"qrcode train_dir: \", train_dir)\n",
    "        qrcode_img_count += stats['img_count'] * weight\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected train_dir: \", train_dir)\n",
    "\n",
    "    face_box_count += stats['face_bbox_count'] * weight\n",
    "    qrcode_box_count += stats['qrcode_bbox_count'] * weight\n",
    "    background_img_count += (stats['none_label_count'] + stats['empty_label_count']) * weight\n",
    "\n",
    "print(f\"face_img_count: {face_img_count}, qrcode_img_count: {qrcode_img_count}, face_box_count: {face_box_count}, qrcode_box_count: {qrcode_box_count}, background_img_count: {background_img_count}\")\n",
    "total_bbox_count = face_box_count + qrcode_box_count\n",
    "print(f\"Face bbox ratio: {face_box_count / total_bbox_count:.2%}, Qrcode bbox ratio: {qrcode_box_count / total_bbox_count:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each img_dir, sample 10 images and display them\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "def get_bbox(img_path):\n",
    "    label_path = (os.path.splitext(img_path)[0] + '.txt').replace('images', 'labels')\n",
    "    if not os.path.exists(label_path):\n",
    "        return {}\n",
    "    \n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # each line is like \"0 0.4524590163934426 0.4192139737991266 0.2754098360655738 0.23580786026200873\"\n",
    "    # class_id center_x center_y width height\n",
    "    bboxes = {}  # {(x1, y1, x2, y2): class_id}\n",
    "    for line in lines:\n",
    "        line = line.strip().split()\n",
    "        x_center, y_center, width, height = map(float, line[1:])\n",
    "        x1 = x_center - width / 2\n",
    "        y1 = y_center - height / 2\n",
    "        x2 = x_center + width / 2\n",
    "        y2 = y_center + height / 2\n",
    "        img_h, img_w, img_c = cv2.imread(img_path).shape\n",
    "        x1 = max(0, x1 * img_w)\n",
    "        y1 = max(0, y1 * img_h)\n",
    "        x2 = min(img_w, x2 * img_w)\n",
    "        y2 = min(img_h, y2 * img_h)\n",
    "        bboxes[(x1, y1, x2, y2)] = int(line[0])\n",
    "    return bboxes\n",
    "\n",
    "red = (255, 0, 0)\n",
    "green = (0, 255, 0)\n",
    "blue = (0, 0, 255)\n",
    "color_map = {0: green, 1: blue}  # 0 is face, 1 is qrcode\n",
    "def sample_images(image_paths, display_rows=2, display_cols=5):\n",
    "    sample_image_paths = random.sample(image_paths, display_rows * display_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(display_rows, display_cols, figsize=(display_cols*3, display_rows*3))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(sample_image_paths):\n",
    "        img_path = img_path.strip()\n",
    "        bboxes = get_bbox(img_path)\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                axes[i].text(0.5, 0.5, f\"Failed to load\\n{os.path.basename(img_path)}\", \n",
    "                             ha='center', va='center', color='red')\n",
    "            else:\n",
    "                # Convert BGR to RGB for proper display and draw bboxes\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                axes[i].imshow(img)\n",
    "                for bbox, class_id in bboxes.items():\n",
    "                    color = color_map[class_id]\n",
    "                    cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 3)\n",
    "\n",
    "                axes[i].imshow(img)\n",
    "            # axes[i].set_title(f\"Image {i+1}\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[i].text(0.5, 0.5, f\"Error: {str(e)}\", ha='center', va='center', color='red')\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "for img_dir, img_paths in list(dt_val.items()):\n",
    "    fig = sample_images(img_paths)\n",
    "    plt.suptitle(img_dir, fontsize=10)\n",
    "    plt.subplots_adjust(top=0.9, wspace=0.1, hspace=0.1)\n",
    "    # plt.tight_layout()\n",
    "    # fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
